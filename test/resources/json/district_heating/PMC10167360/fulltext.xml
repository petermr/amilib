<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" article-type="research-article" dtd-version="1.3"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">10167360</article-id><article-id pub-id-type="pmid">37156854</article-id><article-id pub-id-type="publisher-id">34146</article-id><article-id pub-id-type="doi">10.1038/s41598-023-34146-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Toward explainable heat load patterns prediction for district heating</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Dang</surname><given-names>L. Minh</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Shin</surname><given-names>Jihye</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Yanfen</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Tightiz</surname><given-names>Lilia</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Nguyen</surname><given-names>Tan N.</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author"><name><surname>Song</surname><given-names>Hyoung-Kyu</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Moon</surname><given-names>Hyeonjoon</given-names></name><address><email>hmoon@sejong.ac.kr</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.263333.4</institution-id><institution-id institution-id-type="ISNI">0000 0001 0727 6358</institution-id><institution>Department of Information and Communication Engineering and Convergence Engineering for Intelligent Drone, </institution><institution>Sejong University, </institution></institution-wrap>Seoul, Republic of Korea </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.263333.4</institution-id><institution-id institution-id-type="ISNI">0000 0001 0727 6358</institution-id><institution>Department of Artificial Intelligence, </institution><institution>Sejong University, </institution></institution-wrap>Seoul, Republic of Korea </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.263333.4</institution-id><institution-id institution-id-type="ISNI">0000 0001 0727 6358</institution-id><institution>Department of Computer Science and Engineering, </institution><institution>Sejong University, </institution></institution-wrap>Seoul, Republic of Korea </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.256155.0</institution-id><institution-id institution-id-type="ISNI">0000 0004 0647 2973</institution-id><institution>School of Computing, </institution><institution>Gachon University, </institution></institution-wrap>1342 Seongnam-daero, Sujeong-gu, Seongnam-si, Gyeonggi-do 13120 Republic of Korea </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.263333.4</institution-id><institution-id institution-id-type="ISNI">0000 0001 0727 6358</institution-id><institution>Department of Architectural Engineering, </institution><institution>Sejong University, </institution></institution-wrap>209 Neungdong-ro, Gwangjin-gu, Seoul, 05006 Republic of Korea </aff></contrib-group><pub-date pub-type="epub"><day>8</day><month>5</month><year>2023</year></pub-date><pub-date pub-type="pmc-release"><day>8</day><month>5</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>13</volume><elocation-id>7434</elocation-id><history><date date-type="received"><day>6</day><month>1</month><year>2023</year></date><date date-type="accepted"><day>25</day><month>4</month><year>2023</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2023</copyright-statement><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Heat networks play a vital role in the energy sector by offering thermal energy to residents in certain countries. Effective management and optimization of heat networks require a deep understanding of users' heat usage patterns. Irregular patterns, such as peak usage periods, can exceed the design capacities of the system. However, previous work has mostly neglected the analysis of heat usage profiles or performed on a small scale. To close the gap, this study proposes a data-driven approach to analyze and predict heat load in a district heating network. The study uses data from over eight heating seasons of a cogeneration DH plant in Cheongju, Korea, to build analysis and forecast models using supervised machine learning (ML) algorithms, including support vector regression (SVR), boosting algorithms, and multilayer perceptron (MLP). The models take weather data, holiday information, and historical hourly heat load as input variables. The performance of these algorithms is compared using different training sample sizes of the dataset. The results show that boosting algorithms, particularly XGBoost, are more suitable ML algorithms with lower prediction errors than SVR and MLP. Finally, different explainable artificial intelligence approaches are applied to provide an in-depth interpretation of the trained model and the importance of input variables.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Energy harvesting</kwd><kwd>Mathematics and computing</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2023</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">District heating (DH) has risen as a crucial energy supply infrastructure in order to effectively provide heat and cooling to consumers over the last few decades<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. DH is superior in many aspects compared to other energy supply options, which include having a lower carbon footprint, the integration of multiple heat sources, and high energy throughput. The latest fourth and fifth generations of DH can utilize several heat sources, which include combined heat and power (CHP), gas boilers, water-source heat pumps (HPs), ground-source HPs, and solar energy-based HPs. The recent literature focused more on developing simulation frameworks and effective approaches in regards to designing and optimizing DH systems in terms of the economic and energetic factors, which is due to the fast development of DH technologies<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR3">3</xref></sup>. Storage technology is also a hot topic, because it helps decouple heat production and the demand to increase DH efficiency<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>. The following articles<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR5">5</xref></sup> were reviewed in order to obtain the latest information about DH networks.</p><p id="Par3">The heat usage pattern analysis has become increasingly essential as the number of end-users increases, because it greatly impacts the entire network's efficiency. Variations in the heat usage behavior from the consumers' side lead to variations in the heat usage pattern of a single substation, which is a major matter for accurate and efficient DH management and operation<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. For example, the substantial temperature difference between the summer and the winter significantly influences the users' heat demand. In addition, the hourly heat demand also varies between households, which causes heat demand variation at the substation<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>.</p><p id="Par4">An accurate heat demand prediction framework is imperative in order to effectively manage DH networks<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. First, it facilitates the optimization of the overall heat production, minimizes the heat loss, and optimizes the operating costs. Second, the distribution temperature is provided at an appropriate range in order to predict the real-time heat usage using the heat demand forecast model. As a result, the number of studies proposed in regards to predicting the heat demand has been increasing. A heat demand analysis can generally be divided into model-based and data correlation categories<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>. The data correlation approach mainly depends on building functional correlations of the DH parameters in order to develop a heat usage profile for each substation or building. The model-based technique relies on machine learning (ML) algorithms in order to effectively learn the representative patterns using the historical heat load data<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. The data correlation approach offers higher accuracy than the model-based approach, but it is time-consuming and laborious due to each building/substation having a unique heat usage profile that needs to be constructed. The performance of the model-based heat usage prediction algorithm has become significantly better, which is due to the huge advancements in artificial intelligence (AI) and big data over the past few decades<sup><xref ref-type="bibr" rid="CR9">9</xref>,<xref ref-type="bibr" rid="CR10">10</xref></sup>.</p><p id="Par5">The heat usage prediction, heat loss estimation, and abnormality analysis based on the energy signature (ES) have been increasingly investigated in recent years, which have shown promising results<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR12">12</xref></sup>. However, these studies mainly used outdoor temperature as the main feature in order to discover the heat demand pattern. Other studies focused on peak usage forecasting with the ultimate objective of optimizing the energy usage and DH management<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. These studies, which are similar to the ES, failed to consider the meteorological data or the end-user behaviors. Potential influencers of the heat demand patterns can be divided into three main factors, which include meteorology, behaviors, and time<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. Some common meteorological data that potentially affects heat demand are humidity, solar irradiation, outdoor temperatures, and the wind flow speed<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. Time factor involves all time-related parameters, which include hours, days, months, and years. The social behaviors of the end-users are also a crucial influencer of the heat load variation, which can be affected by both meteorological and time factors<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. These three main factors significantly influence the heat demand patterns.</p><p id="Par6">There has been considerable interest in the research area of heat load forecasting for DH, as indicated by numerous recent studies. Idowu et al.<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> examined a range of supervised ML algorithms in order to perform heat load prediction up to 48&#x000a0;h in advance. The experimental results revealed that conventional ML algorithms, such as SVM and linear regression, achieved the lowest normalized root mean square error when compared to other algorithms. In another study, Boudreau et al. found that ensemble models provided significantly better prediction accuracy than base ML models when it came to predicting peak power demand and next-day building energy usage<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>.</p><p id="Par7">Several studies have delved into specific aspects of DH systems. For example, Saloux et al. explored the application of ML algorithms for predicting the aggregated heating usage of a community. They concluded that the models' performance could be significantly enhanced by considering other crucial factors, such as time of day, systematic variables, and temperature<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. L&#x000f3;pez et al. focused on the impact of specific days, such as holidays or festive periods, on the load curve, and determined that such events could considerably affect the heat usage pattern<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>. Moreover, a case study of a large DH network over several heating seasons revealed that the primary force of heat demand were the various operation settings during daytime (night shutdown and night temperature setback) and the outdoor temperature<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>.</p><p id="Par8">Despite the numerous issues addressed and methods discussed in existing literature on heat load prediction in DH networks, further research is needed to explore important external factors such as holiday and weather conditions, which could be utilized as input to improve the models' accuracy<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. Additionally, while previous work has showed the high predictive performance of ML algorithms for heat demand, they have not provided a clear explanation of why the model achieved good performance, as well as which features are important and their correlation with the models<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>.</p><p id="Par9">This research is proposed in order to improve the heat usage prediction via an in-depth analysis of the dataset to figure out the potential factors that impact the heat demand. The main contributions include (a) performing a data analysis prior to the training process to help thoroughly understand the dataset, (b) training and comparing different ML models in order to obtain the best hourly heat load prediction model, and (c) offering detailed explanations about what features were imperative to the model prediction, which were overlooked in the previous studies.</p><p id="Par10">The remainder of the manuscript is outlined as follows. Section &#x0201c;<xref rid="Sec2" ref-type="sec">Dataset description</xref>&#x0201d; gives a detailed description of the proposed heat demand dataset. After that, the Section &#x0201c;<xref rid="Sec3" ref-type="sec">Methodology</xref>&#x0201d; outlines all processes involved in heat demand prediction. Several experiments are performed in Section &#x0201c;<xref rid="Sec11" ref-type="sec">Experimental results</xref>&#x0201d; to comprehensively assess the proposed framework. Next, the Section &#x0201c;<xref rid="Sec17" ref-type="sec">Discussion</xref>&#x0201d; discusses the findings and provides a detailed analysis of the study. Finally, we conclude the study and offer future work in the Section &#x0201c;<xref rid="Sec20" ref-type="sec">Conclusion</xref>&#x0201d;.</p><sec id="Sec2"><title>Dataset description</title><p id="Par11">The dataset that is described in this research was the hourly heat demand from an eco-friendly liquefied natural gas (LNG)-based cogeneration plant in the Cheongju region, Korea. The plant produces around 76.5 Gigacalories (Gcal) of local heating to the distribution grid. Gcal is a common heat load unit, which measures the heat energy in the heating plants. The LNG-powered plant is more efficient and environmentally friendly for the generation of thermal energy, which has been reported to produce over 70% less emission than coal or oil sources.</p><p id="Par12">The dataset introduced in this study includes the hourly heat usage from January 2012 to December 2020 of the residents from a region, which spans eight heating seasons from November to April. The heat usage profile suggests the amount of heat that is transmitted from the plant to the consumers at a specific duration, which mainly involves space heating (SH) and domestic hot water (DHW). The corresponding hourly historical weather data was also collected as an additional feature in order to discover the potential connections with the heat load patterns in addition to the heat load data. A holiday feature that indicates whether the day under consideration is a holiday is also added in order to investigate the end-user behaviors. The three main features that belong to the weather data include wind flow speed, humidity, and outdoor temperature. The collected heat usage dataset is used to study the hourly heat load patterns and provides some explanations for the model's predictions. The minimum, maximum, mean and standard deviation for each variable are described in Table <xref rid="Tab1" ref-type="table">1</xref>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Description of important observations with possible values for the variables in the proposed dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Name</th><th align="left">Minimum|maximum</th><th align="left">Mean|standard deviation</th><th align="left">Unit</th></tr></thead><tbody><tr><td align="left">Date</td><td align="left">01/01/2012|01/01/2022</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td></tr><tr><td align="left">Wind speed</td><td align="left">0|8.7</td><td align="left">1.47|0.93</td><td align="left">m/s</td></tr><tr><td align="left">Humidity</td><td align="left">7|100</td><td align="left">61.32|20.02</td><td align="left">%</td></tr><tr><td align="left">Outdoor temperature</td><td align="left">&#x02212;&#x000a0;16.5|38.1</td><td align="left">13.75|10.83</td><td align="left">&#x000b0;C</td></tr><tr><td align="left">Holiday</td><td align="left">0 (normal day)|1 (holiday)</td><td align="left">0.32|0.46</td><td align="left">&#x02013;</td></tr><tr><td align="left">Heat load</td><td align="left">0|317</td><td align="left">65.89|52.92</td><td align="left">Gcal</td></tr></tbody></table></table-wrap></p><p id="Par13">In summary, 8760 hourly heat load profiles and their corresponding historical temperature data are obtained yearly. Therefore, a total of 87,672 entries, which include date and time, holiday, wind flow speed, humidity, and temperature, are used as the input variables, and the heat load profiles are used as the target variables. The data entries from 2012 to 2020 were used as the training set, whereas the hourly heat usage of 2021 was applied in order to test the model&#x02019;s performance.</p></sec></sec><sec id="Sec3"><title>Methodology</title><p id="Par14">Figure&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> depicts the three components of the hourly heat usage prediction system, which are (a) data preprocessing, (b) pattern analysis and data partitioning, and (c) explainable heat load forecasting.<list list-type="bullet"><list-item><p id="Par15">Data preprocessing: There is a high possibility that the structured data may contain some common issues with data preprocessing, such as duplicate data, missing data, and negative data due to human errors, which can affect the system's performance. As a result, it is a prerequisite before the data analysis and training processes to fix all errors and standardize the data.</p></list-item><list-item><p id="Par16">Pattern analysis and data partitioning: Heat usage patterns play an important role in regards to enabling specialists to study consumer behavior. The distinctive patterns of the dataset are discovered in this section by using various data analysis approaches in order to thoroughly analyze the dataset before the training phase. The dataset is then divided into training and testing sets.</p></list-item><list-item><p id="Par17">Explainable heat load prediction: Different ML algorithms were trained in order to forecast the hourly heat usage. Some explainable artificial intelligence (XAI) approaches are finally implemented in order to interpret the model&#x02019;s predictions.</p></list-item></list><fig id="Fig1"><label>Figure 1</label><caption><p>Description of the primary components of the heat usage patterns analysis framework.</p></caption><graphic xlink:href="41598_2023_34146_Fig1_HTML" id="MO1"/></fig></p><sec id="Sec4"><title>Data preprocessing</title><sec id="Sec5"><title>Data cleaning</title><p id="Par18">The structured data-related issues, such as missing and duplicated data are unavoidable during the data collection, and they can negatively affect the model's performance if not appropriately corrected. Data cleansing is therefore conducted in order to detect and fix error records in regards to the humidity, wind speed, outdoor temperature, and hourly heat usage data. There are various data cleaning processes, and the two main processes that were performed in this study include removing duplications and fixing the missing values. The dataset is loaded as a data frame using pandas, a famous data manipulation and analysis library. After that, data inconsistencies can be automatically detected using pandas-supported functions.</p><p id="Par19">Standard techniques, such as moving average (MA) and imputation, are usually employed in order to correct the missing data. This study applied the exponential weighted moving average (EWMA) technique<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>, which is an extension of the MA algorithm. EWMA considers the recent data points to be significantly important with a higher weight, whereas the data points in the further past receive an exponentially lower weight. Moreover, the EWMA method can be effectively applied due to the nature of the dataset, and the differences between the two consecutive data points are considered minor. The EWMA can be described as follows.<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${E}_{t}=\alpha \times {x}_{t}+(1-\alpha )\times {E}_{t-1}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><graphic xlink:href="41598_2023_34146_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq1"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${E}_{t}$$\end{document}</tex-math><mml:math id="M4"><mml:msub><mml:mi>E</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq1.gif"/></alternatives></inline-formula> indicate the computed value at time t based on the EWMA technique. <inline-formula id="IEq2"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{t}$$\end{document}</tex-math><mml:math id="M6"><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq2.gif"/></alternatives></inline-formula> is the value of the series in the current period. <inline-formula id="IEq3"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${E}_{t-1}$$\end{document}</tex-math><mml:math id="M8"><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq3.gif"/></alternatives></inline-formula> is the EWMA at the previous time period. Finally, <inline-formula id="IEq4"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha $$\end{document}</tex-math><mml:math id="M10"><mml:mi>&#x003b1;</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq4.gif"/></alternatives></inline-formula> is the smoothing factor, which ranges between 0 and 1 and controls the influence of the current value <inline-formula id="IEq5"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{t}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq5.gif"/></alternatives></inline-formula> on the <inline-formula id="IEq6"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${E}_{t}$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mi>E</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq6.gif"/></alternatives></inline-formula>. A larger <inline-formula id="IEq7"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha $$\end{document}</tex-math><mml:math id="M16"><mml:mi>&#x003b1;</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq7.gif"/></alternatives></inline-formula> places more weight on recent observations and results in a more reactive EWMA, while a smaller <inline-formula id="IEq8"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha $$\end{document}</tex-math><mml:math id="M18"><mml:mi>&#x003b1;</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq8.gif"/></alternatives></inline-formula> results in a smoother EWMA.</p></sec><sec id="Sec6"><title>Feature engineering</title><p id="Par20">Feature engineering is the process of selecting, extracting, and transforming relevant features or variables from raw data to enhance the performance of ML algorithms. The goal of feature engineering is to provide ML algorithms with informative and discriminative features that can help them better understand the underlying patterns and relationships in the data. Two main processes in the feature engineering process are standardization and feature transformation.</p><p id="Par21">The regression model fitting and learned function can be negatively affected by structured data, and it eventually creates a bias when numerical features with different scales are fed into the model<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. The normalization/standardization techniques therefore need to be implemented in order to normalize the input features. Min&#x02013;max normalization and standardization are two common feature scaling approaches<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. The heat usage dataset that is applied to fit the model contains peak heat load on some specific periods, which are outliers, and it has an essential role during the training process. The min&#x02013;max normalization likely lowers the impact of those outliners by transforming all features into a range between 0 and 1. The standardization therefore scales the features in order to have a zero mean, and a standard deviation of 1 is implemented in this study.</p><p id="Par22">Feature transformation is necessary for structured data in order to convert categorical inputs into numerical inputs, because most ML models work with numerical data. The holiday variable is categorical, because it has two distinctive values, which represent whether a particular day is a regular day or a holiday. As a result, one-hot encoding, which creates a binary representation of the categorical feature, is applied in order to transform the holiday feature<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>. For instance, when a specific day is a holiday, the value for the holiday binary variable is set to 1, and the regular binary variable is 0.
</p></sec></sec><sec id="Sec7"><title>Pattern analysis and data partitioning</title><sec id="Sec8"><title>Pattern analysis</title><sec id="Sec9"><title>Heat network during the summer season</title><p id="Par23">The investigation of the heat network in the summer season, which spans from June to August, gives some exciting insights into the town's heat usage. Figure&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref> illustrates the hourly heat demand distribution density for the summer months from 2012 to 2021. The average heat demand in the summer mainly involves the DHW consumption and the network heat losses. It can generally be seen that there was less heat demand in the distant past compared to the recent years. For instance, a roughly similar distribution can be observed for the following years, which include from 2012 to 2016, with the average heat demand being around 20 Gcal. However, the average heat demand increased to around 30 Gcal, which included the more recent years from 2019 to 2021, with some higher heat demands being related to particular heat usage patterns. Moreover, there has been a gradually increasing trend in the average heat usage of over 40 Gcal in recent years, and the year 2021 shows the highest density.<fig id="Fig2"><label>Figure 2</label><caption><p>Distribution density plot of hourly heat demand during the summer season (Jun.&#x02013;Aug.).</p></caption><graphic xlink:href="41598_2023_34146_Fig2_HTML" id="MO2"/></fig></p></sec><sec id="Sec10"><title>Heat network during the winter season</title><p id="Par24">The chart in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> illustrates the network's energy consumption on an hourly basis during the winter season spanning from November to March. The chart depicts three distinct patterns for three different time periods: daytime (06:00&#x02013;18:00), nighttime (22:00&#x02013;05:00), and peak hours (19:00&#x02013;21:00). The scatter plot reveals that the consumers tend to use more heat during the peak time at the same temperature level compared to the nighttime and daytime. Moreover, the lower the outside temperature, the higher the heat load that is required.<fig id="Fig3"><label>Figure 3</label><caption><p>Scatter plot of the outdoor temperature and the heat usage during the winter season (Nov.&#x02013;Mar.).</p></caption><graphic xlink:href="41598_2023_34146_Fig3_HTML" id="MO3"/></fig></p></sec><sec id="Sec11"><title>Some heat load patterns for each season of the year</title><p id="Par25">A typical hourly heat load pattern for each season can be observed in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>. The spring, fall, and winter seasons have similar variations in the hourly time scale, which is caused by the social behavior of the end-users. Reduced heat loads can be observed in the daytime, which is due to solar radiation that leads to higher daytime temperatures. The highest heat load during the daytime occurs around 8 am in order to prepare the space heating in offices and commercial buildings. The heat demand usually peaks between 19:00 and 21:00 because of the low temperature at night, which requires more heat for SH and DHW. DHW is a major part of the heat demand in the summer, when a tiny difference in the heat variation can be observed.<fig id="Fig4"><label>Figure 4</label><caption><p>Average weekly heat load patterns during the four season periods.</p></caption><graphic xlink:href="41598_2023_34146_Fig4_HTML" id="MO4"/></fig></p></sec></sec><sec id="Sec12"><title>Data partitioning</title><p id="Par26">Data partitioning is a fundamental step required before training and evaluating the model. After preprocessing, the data is split into two sets: the training set and the testing set. The training set is utilized to train and optimize the model, while the testing set is typically employed to assess the algorithms' performance across various scenarios. This study used the heat usage profiles between 2012 and 2020 as the training set, whereas the heat load profiles from 2021 were used for the testing. Each training or testing sample consists of day, hour, outdoor temperature, humidity, windspeed, and holiday as the input variables, while the output is the hourly heat usage corresponding to that particular input.</p></sec></sec><sec id="Sec13"><title>Explainable heat load prediction</title><p id="Par27">This section presents the main concepts behind boosting, support vector regression (SVR)<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>, and multilayer perceptron (MLP) algorithms<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> that were implemented for the heat demand forecasting.</p><sec id="Sec14"><title>Boosting algorithms</title><p id="Par28">Boosting algorithm belongs to the ensemble approach, which sequentially adds multiple weak learners. Each weak learner is added by using the learned information from its predecessor, and it tries to correct the errors that are predicted by them. A weak learner can be any learning algorithm that offers a slightly better performance than random guessing. Two standard boosting approaches are gradient boosting and adaptive boosting<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>.<list list-type="bullet"><list-item><p id="Par29">Adaptive boosting: The adaptive boosting (AdaBoost) algorithm was proposed by sequentially adding weak learners, which involved using decision trees, and attempting in order to correct the wrongly predicted samples by applying a bigger weight to them during the training process of the latter weak learners. The AdaBoost model's final output is the weighted median.</p></list-item><list-item><p id="Par30">Gradient boosting: AdaBoost assigns new instance weights whenever a new weak learner is added, but gradient boosting aims to fit the new predictor to the residual errors that are caused by the prior predictor with the primary objective of minimizing a loss function<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. Some popular gradient boosting algorithms include LightGBM and XGBoost.</p></list-item></list></p><p id="Par31">XGBoost leverages the feature distribution across all data points to narrow down the search space of potential feature splits. The objective of the XGBoost algorithm can be expressed as:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$objective=L+\mu $$\end{document}</tex-math><mml:math id="M20" display="block"><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003bc;</mml:mi></mml:mrow></mml:math><graphic xlink:href="41598_2023_34146_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where the predictive ability of XGBoost is determined by the loss function <inline-formula id="IEq9"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L$$\end{document}</tex-math><mml:math id="M22"><mml:mi>L</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq9.gif"/></alternatives></inline-formula>, while the regularization term <inline-formula id="IEq10"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M24"><mml:mi>&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq10.gif"/></alternatives></inline-formula> is used to manage overfitting. <inline-formula id="IEq11"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu $$\end{document}</tex-math><mml:math id="M26"><mml:mi>&#x003bc;</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq11.gif"/></alternatives></inline-formula> is determined by the number of observers and their prediction threshold in the ensemble model. Since the problem in question belongs to regression analysis, the root mean squared error (RMSE) is used as the loss function <inline-formula id="IEq12"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L$$\end{document}</tex-math><mml:math id="M28"><mml:mi>L</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq12.gif"/></alternatives></inline-formula>.</p></sec><sec id="Sec15"><title>Support vector regression (SVR)</title><p id="Par32">Unlike typical regression algorithms that seek to minimize the sum of squared errors between actual and predicted values, SVR attempts to identify the optimal hyperplane within a user-defined threshold value. The threshold value is the distance between the boundary line and the hyperplane. Heat demand prediction is a complex non-linear topic, because it has multiple input variables. To address non-linearity in the initial feature space and treat it as a linear problem in the high-dimensional feature space, SVR requires the use of a non-linear kernel. The Gaussian Radial Basis kernel (RBF) was used in this study as the default kernel for SVR.</p></sec><sec id="Sec16"><title>Multilayer perceptron (MLP)</title><p id="Par33">Multilayer perceptron (MLP) belongs to the feedforward artificial neural networks (ANN) category. MLP's fundamental structure consists of an input layer, one or more hidden layers with neurons, and an output layer that are stacked in sequence. The neuron is the primary computing component of MLP, and neurons from the current layers fully connect to neurons from the next layer. The inputs are added to the initial weights, fed into an activation function, and propagated to the next layer.</p></sec></sec></sec><sec id="Sec17"><title>Experimental results</title><p id="Par34">This section shows all experiments that were conducted to determine the most suitable algorithm for predicting heat usage. In addition, various XAI techniques were also conducted in order to provide an in-depth analysis of the trained models.</p><p id="Par35">The heat load prediction models were constructed and trained on scikit-learn<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>, a Python-based open-source ML library. Three main explainable AI libraries for analyzing the data include partial dependence plot<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> (PDP), which is a global and model-agnostic XAI algorithm, local interpretable model-agnostic explanations<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> (LIME), which create a local model approximation of the model around the prediction of interest, and shapley additive explanations<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> (SHAP), which employ a game-theoretic approach.</p><sec id="Sec18"><title>Evaluation metrics</title><p id="Par36">Three standard evaluation metrics were computed, which included the coefficient of determination (<inline-formula id="IEq13"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${R}^{2}$$\end{document}</tex-math><mml:math id="M30"><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq13.gif"/></alternatives></inline-formula>), mean squared error (MSE), and mean absolute error (MAE) in order to evaluate the heat demand forecasting. MSE is computed by averaging the squared difference between the predicted values and actual values for all the training samples<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. On the other hand, MAE is the average of the absolute differences between the predicted values and true values. While MSE measures the standard deviation of residuals, MAE calculates the average of the residuals in the dataset. <inline-formula id="IEq14"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${R}^{2}$$\end{document}</tex-math><mml:math id="M32"><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq14.gif"/></alternatives></inline-formula> is computed by determining the proportion of the dependent variable's variance predicted by the algorithm. The lower the MSE and MAE scores, the better the model&#x02019;s performance. However, a higher value of <inline-formula id="IEq15"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${R}^{2}$$\end{document}</tex-math><mml:math id="M34"><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq15.gif"/></alternatives></inline-formula> is considered better. The three metrics can be formulated as follows.<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MSE=\frac{1}{N}{\sum }_{i=1}^{N}{\left({y}_{i}-{\widehat{y}}_{i}\right)}^{2}$$\end{document}</tex-math><mml:math id="M36" display="block"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><graphic xlink:href="41598_2023_34146_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${R}^{2}= 1-\frac{\sum {\left({y}_{i}-{\widehat{y}}_{i}\right)}^{2}}{\sum {\left({y}_{i}-\overline{y }\right)}^{2}}$$\end{document}</tex-math><mml:math id="M38" display="block"><mml:mrow><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x02211;</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mo>&#x02211;</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mover><mml:mi>y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2023_34146_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MAE=\frac{1}{N}{\sum }_{i=1}^{N}\left|{y}_{i}-{\widehat{y}}_{i}\right|$$\end{document}</tex-math><mml:math id="M40" display="block"><mml:mrow><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mfenced close="|" open="|"><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="41598_2023_34146_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq16"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N$$\end{document}</tex-math><mml:math id="M42"><mml:mi>N</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq16.gif"/></alternatives></inline-formula> is the total number of training samples. <inline-formula id="IEq17"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}_{i}$$\end{document}</tex-math><mml:math id="M44"><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq17.gif"/></alternatives></inline-formula> indicates the actual value, <inline-formula id="IEq18"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{y}}_{i}$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq18.gif"/></alternatives></inline-formula> means the predicted value of the <inline-formula id="IEq19"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M48"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq19.gif"/></alternatives></inline-formula> th profile, and <inline-formula id="IEq20"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overline{y }$$\end{document}</tex-math><mml:math id="M50"><mml:mover><mml:mi>y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq20.gif"/></alternatives></inline-formula> is the mean value of <inline-formula id="IEq21"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y$$\end{document}</tex-math><mml:math id="M52"><mml:mi>y</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq21.gif"/></alternatives></inline-formula>.</p></sec><sec id="Sec19"><title>Hyperparameter fine-tuning</title><p id="Par37">Five regression models were implemented in this study in order to perform the heat demand forecasting, which included SVR, AdaBoost, XGBoost, LightGBM, and MLP. Each model has its crucial hyperparameters that must be determined before the training. The hyperparameters control the training behavior of the learning algorithms, and they considerably influence the model's performance.</p><p id="Par38">Table <xref rid="Tab2" ref-type="table">2</xref> shows the hyperparameters and the value range for each hyperparameter that is required by the five models. A grid search method was conducted next on the different combinations of the hyperparameters of each algorithm in order to explore the most suitable hyperparameter combination that helps the algorithm obtain the best performance.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Initial hyperparameter value ranges and the optimal hyperparameter value for each algorithm.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Model</th><th align="left">Hyper parameter</th><th align="left">Definition</th><th align="left">Value ranges</th><th align="left">Optimal value</th></tr></thead><tbody><tr><td align="left" rowspan="2">AdaBoost</td><td align="left"><inline-formula id="IEq22"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M54"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq22.gif"/></alternatives></inline-formula></td><td align="left">Number of estimators</td><td align="left">50, 100, 150, 200</td><td align="left">50</td></tr><tr><td align="left"><inline-formula id="IEq23"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma $$\end{document}</tex-math><mml:math id="M56"><mml:mi>&#x003c3;</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq23.gif"/></alternatives></inline-formula></td><td align="left">Learning rate</td><td align="left"><inline-formula id="IEq24"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{-3}$$\end{document}</tex-math><mml:math id="M58"><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq24.gif"/></alternatives></inline-formula>, <inline-formula id="IEq25"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{-2}, {10}^{-1}$$\end{document}</tex-math><mml:math id="M60"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq25.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq26"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{-1}$$\end{document}</tex-math><mml:math id="M62"><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq26.gif"/></alternatives></inline-formula></td></tr><tr><td align="left" rowspan="4">XGBoost</td><td align="left"><inline-formula id="IEq27"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M64"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq27.gif"/></alternatives></inline-formula></td><td align="left">Number of estimators</td><td align="left">50, 100, 150, 200</td><td align="left">50</td></tr><tr><td align="left"><inline-formula id="IEq28"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{tree}$$\end{document}</tex-math><mml:math id="M66"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">tree</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq28.gif"/></alternatives></inline-formula></td><td align="left">Max depth of a tree</td><td align="left">3, 6, 9, 12, 15</td><td align="left">9</td></tr><tr><td align="left"><inline-formula id="IEq29"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\upgamma $$\end{document}</tex-math><mml:math id="M68"><mml:mi mathvariant="normal">&#x003b3;</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq29.gif"/></alternatives></inline-formula></td><td align="left">Min loss reduction</td><td align="left">0, 0.1, 0.2, 0.3</td><td align="left">0</td></tr><tr><td align="left">subsample</td><td align="left">Subsample ratio of the training instances</td><td align="left">0.5, 1, 2</td><td align="left">1</td></tr><tr><td align="left" rowspan="4">LightGBM</td><td align="left">num_leaves</td><td align="left">Max number of nodes per tree</td><td align="left">21, 31, 41, 51</td><td align="left">31</td></tr><tr><td align="left"><inline-formula id="IEq30"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma $$\end{document}</tex-math><mml:math id="M70"><mml:mi>&#x003c3;</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq30.gif"/></alternatives></inline-formula></td><td align="left">Learning rate</td><td align="left"><inline-formula id="IEq31"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{-3}$$\end{document}</tex-math><mml:math id="M72"><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq31.gif"/></alternatives></inline-formula>, <inline-formula id="IEq32"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{-2}, {10}^{-1}$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq32.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq33"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{-1}$$\end{document}</tex-math><mml:math id="M76"><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq33.gif"/></alternatives></inline-formula></td></tr><tr><td align="left"><inline-formula id="IEq34"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M78"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq34.gif"/></alternatives></inline-formula></td><td align="left">Number of estimators</td><td align="left">50, 100, 150, 200</td><td align="left">100</td></tr><tr><td align="left"><inline-formula id="IEq35"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{tree}$$\end{document}</tex-math><mml:math id="M80"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="italic">tree</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq35.gif"/></alternatives></inline-formula></td><td align="left">Max depth of a tree</td><td align="left">2, 3, 4, 5, 6</td><td align="left">4</td></tr><tr><td align="left" rowspan="2">SVR</td><td align="left"><inline-formula id="IEq36"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{C}$$\end{document}</tex-math><mml:math id="M82"><mml:mi mathvariant="normal">C</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq36.gif"/></alternatives></inline-formula></td><td align="left">Regularization parameter</td><td align="left"><inline-formula id="IEq37"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{0}, {10}^{1}, {10}^{2}, {10}^{3}$$\end{document}</tex-math><mml:math id="M84"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mn>0</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq37.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq38"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{0}$$\end{document}</tex-math><mml:math id="M86"><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mn>0</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq38.gif"/></alternatives></inline-formula></td></tr><tr><td align="left"><inline-formula id="IEq39"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\upgamma $$\end{document}</tex-math><mml:math id="M88"><mml:mi mathvariant="normal">&#x003b3;</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq39.gif"/></alternatives></inline-formula></td><td align="left">Kernel coefficient</td><td align="left"><inline-formula id="IEq40"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{-6}, {10}^{-3}$$\end{document}</tex-math><mml:math id="M90"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq40.gif"/></alternatives></inline-formula>,<inline-formula id="IEq41"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{-1}$$\end{document}</tex-math><mml:math id="M92"><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq41.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq42"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{-3}$$\end{document}</tex-math><mml:math id="M94"><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq42.gif"/></alternatives></inline-formula></td></tr><tr><td align="left" rowspan="4">MLP</td><td align="left"><inline-formula id="IEq43"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma $$\end{document}</tex-math><mml:math id="M96"><mml:mi>&#x003c3;</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq43.gif"/></alternatives></inline-formula></td><td align="left">Learning rate</td><td align="left"><inline-formula id="IEq44"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{-3}$$\end{document}</tex-math><mml:math id="M98"><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq44.gif"/></alternatives></inline-formula>, <inline-formula id="IEq45"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{-2}, {10}^{-1}$$\end{document}</tex-math><mml:math id="M100"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq45.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq46"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${10}^{-2}$$\end{document}</tex-math><mml:math id="M102"><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq46.gif"/></alternatives></inline-formula></td></tr><tr><td align="left"><inline-formula id="IEq47"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${nh}_{i}$$\end{document}</tex-math><mml:math id="M104"><mml:msub><mml:mrow><mml:mi mathvariant="italic">nh</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq47.gif"/></alternatives></inline-formula></td><td align="left">Number of neurons in hidden layer ith</td><td align="left">50, 100, 150, 200</td><td align="left">150</td></tr><tr><td align="left"><inline-formula id="IEq48"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{\varphi }}$$\end{document}</tex-math><mml:math id="M106"><mml:mi>&#x003c6;</mml:mi></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq48.gif"/></alternatives></inline-formula></td><td align="left">Activation function</td><td align="left">ReLU, tanh</td><td align="left">ReLU</td></tr><tr><td align="left">B</td><td align="left">Batch size</td><td align="left">8, 16, 32, 64</td><td align="left">32</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec20"><title>Heat usage prediction analysis</title><p id="Par39">Figure&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref> depicts the performance and scalability comparison of five different learning algorithms using the learning curves in order to show the effect of adding more samples during the training process. The experiment involved randomly selecting samples from the training dataset. A training sample include date, outdoor temperature, windspeed, humidity, holiday, and hourly heat demand as the features.<fig id="Fig5"><label>Figure 5</label><caption><p>Heat demand forecasting performance using five different algorithms.</p></caption><graphic xlink:href="41598_2023_34146_Fig5_HTML" id="MO5"/></fig></p><p id="Par40">It can generally be concluded that SVR and MLP were highly sensitive to the dataset size, because they widely fluctuated as more training samples were added. On the other hand, the boosting algorithms, which included AdaBoost, LightGBM, and XGBoost, showed their advantages and effectiveness with a bigger dataset. The three ensemble algorithms exhibited similar trends in variation; the error gradually decreased and eventually stabilized. Low MSE scores of less than 0.02 were obtained for the three boosting algorithms when the training dataset size was over 2000 samples. XGBoost achieved the lowest mean squared error of less than 0.01 among the three algorithms, and it showed its robustness when the number of training samples reached 7000. As a result, XGBoost was utilized as the primary model for the following experiments.</p><p id="Par41">Table <xref rid="Tab3" ref-type="table">3</xref> shows the heat demand forecasting performance using five ML algorithms on the test dataset. All the models generally obtained good performances on the dataset. The boosting algorithms performed better than SVR and MLP. The XGBoost algorithm achieved the highest <inline-formula id="IEq49"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{R}}^{2}$$\end{document}</tex-math><mml:math id="M108"><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq49.gif"/></alternatives></inline-formula>, MSE, and MAE at 0.95, 0.12, and 0.15, respectively. On the other hand, MLP showed the lowest heat usage prediction performance with an MSE value of 0.25 and R2 at 0.89.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Hourly heat load prediction performance for the five ML algorithms on the testing dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Model</th><th align="left">MAE</th><th align="left">MSE</th><th align="left"><inline-formula id="IEq50"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{R}}^{2}$$\end{document}</tex-math><mml:math id="M110"><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq50.gif"/></alternatives></inline-formula></th></tr></thead><tbody><tr><td align="left">AdaBoost</td><td char="." align="char">0.16</td><td char="." align="char">0.14</td><td char="." align="char">0.94</td></tr><tr><td align="left">XGBoost</td><td char="." align="char">0.15</td><td char="." align="char">0.12</td><td char="." align="char">0.95</td></tr><tr><td align="left">LightGBM</td><td char="." align="char">0.18</td><td char="." align="char">0.17</td><td char="." align="char">0.91</td></tr><tr><td align="left">SVR</td><td char="." align="char">0.24</td><td char="." align="char">0.21</td><td char="." align="char">0.92</td></tr><tr><td align="left">MLP</td><td char="." align="char">0.23</td><td char="." align="char">0.25</td><td char="." align="char">0.89</td></tr></tbody></table></table-wrap></p><p id="Par42">Figure&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref> compares the actual and the predicted heat demand for 2021 using the XGBoost model. The heat usage values predicted by the model, which are illustrated by the red line, are roughly similar to the actual heat usage values, which are illustrated by the blue line. Moreover, each month's peak and bottom heat usage were accurately predicted. However, the model performance was significantly affected, which is due to some uncommon end-user's heat usage behaviors.<fig id="Fig6"><label>Figure 6</label><caption><p>Daily heat load prediction results on the testing dataset.</p></caption><graphic xlink:href="41598_2023_34146_Fig6_HTML" id="MO6"/></fig></p></sec><sec id="Sec21"><title>Explainable heat usage prediction</title><p id="Par43">The previous section discussed what model achieved the highest heat usage forecasting performance. However, it is challenging to reveal what features are influential and how they affect the model predictions. As a result, some interesting XAI approaches are implemented in this section in order to attempt to explain how ML models predict the outcomes.</p><p id="Par44">Firstly, three different feature ranking techniques were implemented in order to evaluate each feature's importance in regards to predicting the output heat usage by the model, as displayed in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>. Figure&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>a calculates a feature's relative importance by examining the mean and standard deviation of impurity reduction across each tree. Figure&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>b ranks the feature importance by computing the game's theoretically optimal shapley values<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>. The resulting shapley values provide a measure of the relative importance of each feature in the model prediction for a particular data point. It requires examining every possible feature combination and assessing the marginal impact of each feature on the prediction. Features with higher Shapley values are regarded as more significant. Ranking both approaches reveal that the temperature and month features are crucial, which is valid due to the end-users heat demand pattern being significantly affected by these two features.<fig id="Fig7"><label>Figure 7</label><caption><p>Feature importance analysis for the heat usage prediction model.</p></caption><graphic xlink:href="41598_2023_34146_Fig7_HTML" id="MO7"/></fig></p><p id="Par45">Finally, Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>c visualizes the feature importance assessed by LIME. Positive weights indicate that a feature promotes a positive prediction, while negative weights indicate the opposite. The magnitude of the weight represents the importance of the feature. It is noticeable that a temperature of 4&#x000a0;&#x000b0;C or lower (cold season) presses the model to output a higher heat usage.</p><p id="Par46">The previous experiment indicated that the temperature and month features greatly impacted the model's predictions, but it did not explain exactly how the model was affected. As a result, PDP, was implemented in order to demonstrate a feature's marginal effect on the models' prediction.</p><p id="Par47">Figure&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref> shows how temperature and month together impact heat usage in the form of contour lines. Contour was proved to work best for analyzing the impact of continuous features in the PDP interaction plot<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>.<fig id="Fig8"><label>Figure 8</label><caption><p>PDP interaction plot for the temperature and month features.</p></caption><graphic xlink:href="41598_2023_34146_Fig8_HTML" id="MO8"/></fig></p><p id="Par48">The contour lines, ranging from 0.000 to 150.000, indicate how specific ranges of the two features affect heat usage. A higher value of the contour line implies a greater impact of the two features on heat usage. For example, during the summer season when the average temperature is above 22&#x000a0;&#x000b0;C, the features have a negative influence on the model prediction, resulting in an average heat demand of less than 50 Gcal and a contour line value of under 25.000. On the other hand, contour line values greater than 125.000, corresponding to the winter season with an average temperature of fewer than 2&#x000a0;&#x000b0;C, positively impact the model prediction leading to the average heat usage of over 120 Gcal.</p><p id="Par49">Figure&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref> illustrates how the temperature feature affected the heat demand through the distribution of the actual heat demand via fixed values of the temperature variable. It was observable that the hourly heat load achieved the biggest average value, which was approximately 150 Gcal, occurred when the temperature feature was between -16.5&#x000a0;&#x000b0;C to -0.6&#x000a0;&#x000b0;C, indicating the winter season. Moreover, the hourly heat demand gradually dropped when the temperature rose. The lowest hourly heat demand, around 21 Gcal, was recorded when the temperature ranged from 26.9 to 38.1&#x000a0;&#x000b0;C , which corresponds to the summer season.<fig id="Fig9"><label>Figure 9</label><caption><p>Actual predictions plot for the temperature variable. Distribution of the actual prediction via different variable values.</p></caption><graphic xlink:href="41598_2023_34146_Fig9_HTML" id="MO9"/></fig></p><p id="Par50">Based on the data, we can conclude that the hourly heat demand is directly proportional to the temperature. In the summer, DHW accounts for the majority of the heat demand. In contrast, both DHW and SH contribute to the heat demand during the winter. Additionally, the hourly heat demand is higher during the winter, with temperatures below 10&#x000a0;&#x000b0;C, and lower during the summer, with temperatures above 26&#x000a0;&#x000b0;C.</p></sec><sec id="Sec22"><title>Comparison with similar studies</title><p id="Par51">Numerous studies have been conducted in the past to predict and analyze DH head demand. However, direct comparisons with these studies are difficult due to differences in DH network designs, input data, and architecture implementations or experimental setups. We use operational data from DHS to predict heat usage patterns and compare our results using the XGBoost model, which exhibits the best prediction performance. The recorded MAE value from this study was 15%, which is smaller than the reported MAE of 18.07% by Huang et al<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. In addition, the computed evaluation metrics are also superior to the following reseach<sup><xref ref-type="bibr" rid="CR37">37</xref>,<xref ref-type="bibr" rid="CR38">38</xref></sup>. Specifically, the proposed XGBoost model outperforms the study suggested by Ivanko et al<sup><xref ref-type="bibr" rid="CR38">38</xref></sup> in terms of MSE and correlation coefficient, achieving 12% and 0.95 on the testing set, respectively, compared to MSE of 45.04% and a coefficient of determination of 0.81. In terms of the correlation coefficient, the XGBoost method also shows better hourly prediction performance than the ANN model proposed by B&#x000fc;nning et al<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>, with a correlation coefficient of 0.95 for one hour compared to 0.88.</p></sec></sec><sec id="Sec23"><title>Discussion</title><p id="Par52">This section provides a discussion based on our approach and the obtained results. Furthermore, a discussion about the interpretability of the study is also presented.</p><sec id="Sec24"><title>Model performance</title><p id="Par53">To establish the best heat demand prediction model, five different models were evaluated with varying sizes of training datasets. Then, three evaluation metrics (MSE, MAE, and <inline-formula id="IEq51"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{R}}^{2}$$\end{document}</tex-math><mml:math id="M112"><mml:msup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="41598_2023_34146_Article_IEq51.gif"/></alternatives></inline-formula>) were calculated. Figure&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref> demonstrates the learning trend of these models as the number of training samples increases. When the training dataset size is less than 2000, MLP and SVR exhibit the highest accuracy. However, these models have drawbacks such as the need for sequential data and extended training times, making them more suitable for applications that can handle longer training periods. On the other hand, for larger training datasets (over 2000 samples), the accuracy of the three boosting algorithms is higher. Boosting algorithms, such as AdaBoost and XGBoost, are more appropriate for granular control and frequent updating due to their short training time, stability, and forecasting accuracy. Nonetheless, all models can generate predictions swiftly (within a second) after being trained. Hence, the time required for training and retraining the models is the primary constraint for their overall implementation.</p><p id="Par54">Collinearity, which refers to the correlation between predictor variables, always exists in real-world data<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. However, the impact of collinearity on prediction models varies due to differences in principles. Previously, several approaches have been introduced to address collinearity problems, such as pre-selection based on thresholds, clustering predictors, and regularization techniques. Regularization is a method used to reduce the complexity of the SVM model and prevent overfitting<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. Similarly, boosting-based models like AdaBoost, XGBoost, and LightGBM can effectively handle multicollinearity problems by adjusting the number of variables sampled at each split<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>, which acts as a regularization parameter. In contrast, MLP's ability to withstand collinearity is relatively weak, which may explain its relatively low accuracy.</p><p id="Par55">The way in which heat is distributed varies greatly depending on the size of the DH network, and the proposed framework is appropriate for smaller networks where the behavior of customers has an impact on the load pattern. It is possible to apply the framework to other small-scale DH networks, in order to anticipate the hourly heat demand, as long as records of the hourly heat demand and environmental factors such as wind speed, humidity and temperature are available.</p></sec><sec id="Sec25"><title>Interpretability</title><p id="Par56">Model interpretability for AI models refers to the ability to transform the training and testing processes into logical rules. The model's ability to display the significance and ranking of input variables<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> allows it to exhibit interpretability. The interpretability of a predictive model is crucial in evaluating the rationality of heat demands in a DH network. A lack of conformity to accepted principles in variable importance can indicate model instability or system malfunction<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>. Boosting-based methods are highly interpretable as they do not require the interpretation of tree structures by ML professionals, and each decision corresponds to a logical rule<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. These models can output visual results of variable importance, with the weight and rank of variables differing depending on the model's inherent principles, as displayed in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>. However, temperature and month were consistently the most influential variables, with humidity and holiday having a negligible impact, indicating the limited influence of these variables on heat usage.</p><p id="Par57">On the other hand, SVR and MLP were less interpretable, with MLP being considered a black box method due to its difficulty in identifying the features extracted from each layer of the network. The use of a linear kernel function in SVR leads to a more interpretable model, but models with other kernels can be challenging to interpret<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>.</p></sec></sec><sec id="Sec26"><title>Conclusion</title><p id="Par58">Hourly heat demand forecasting is essential for heating providers to optimize heat production and heat supply operations. This research presents an hourly heat usage prediction system that is based on standard regression algorithms, and it systematically investigates the input features' influence on the models' outcomes.</p><p id="Par59">First, additional weather information, which includes the outdoor temperature, wind flow speed, and humidity of the corresponding hourly historical heat demand, were extracted during the data collection process, and they were used as the input features. After that, various data preprocessing procedures were implemented in order to clean the dataset. The preprocessed dataset was utilized in order to thoroughly analyze the common heat demand patterns. Finally, the dataset was inputted into five well-known regression algorithms, namely SVR, MLP, XGBoost, AdaBoost, and LightGBM, in order to determine what model is the most suitable for the heat usage prediction task based on standard evaluation metrics.</p><p id="Par60">The XGBoost model achieved the lowest MSE via various experiments, which was less than 0.01, and it was robust when the number of samples in the training dataset increased. Finally, various XAI methods, such as SHAP and PDP were applied in order to thoroughly analyze how the model gave a particular prediction. The results showed that temperature and time-related variables are the most critical features that contribute to the model's predictions.</p><p id="Par61">More attention will be directed in the future toward novel heat load prediction techniques, such as multi-step ahead prediction. In addition, collecting a larger dataset with additional variables can improve the performance and efficiency of the model.</p></sec></body><back><fn-group><fn><p><bold>Publisher's note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>This work was supported by the Basic Science Research Program via the National Research Foundation of Korea (NRF) funded by the Ministry of Education (2020R1A6A1A03038540) and by a grant (20212020900150) from "Development and Demonstration of Technology for Customers Bigdata-based Energy Management in the Field of Heat Supply Chain" funded by Ministry of Trade, Industry and Energy of Korean government and by the Institute of Information and Communications Technology Planning and Evaluation (IITP) grant funded by the Korea government (MSIT) (No.2022-0-00106, Development of explainable AI-based diagnosis and analysis frame work using energy demand big data in multiple domains).</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>H.M. and H.S. acquired the funding and supervised the study. Y.L., L.T., and T.N. performed the data collection, preprocessing, and experimental validation. L.D. wrote the original draft. J.S. revised the manuscript. All authors have read and agreed to publish the version of the manuscript.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>The datasets used and/or analysed during the current study available from the corresponding author on reasonable request.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>The source code for all the analyses presented in this study can be found on these GitHub repositories: <ext-link ext-link-type="uri" xlink:href="https://github.com/minhdl93/HeatLoadAnalysis.">https://github.com/minhdl93/HeatLoadAnalysis.</ext-link></p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par62">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lund</surname><given-names>H</given-names></name><name><surname>&#x000d8;stergaard</surname><given-names>PA</given-names></name><name><surname>Chang</surname><given-names>M</given-names></name><name><surname>Werner</surname><given-names>S</given-names></name><name><surname>Svendsen</surname><given-names>S</given-names></name><name><surname>Sorkn&#x000e6;s</surname><given-names>P</given-names></name><name><surname>Thorsen</surname><given-names>JE</given-names></name><name><surname>Hvelplund</surname><given-names>F</given-names></name><name><surname>Mortensen</surname><given-names>BOG</given-names></name><name><surname>Mathiesen</surname><given-names>BV</given-names></name></person-group><article-title>The status of 4th generation district heating: Research and results</article-title><source>Energy</source><year>2018</year><volume>164</volume><fpage>147</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1016/j.energy.2018.08.206</pub-id></element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barone</surname><given-names>G</given-names></name><name><surname>Buonomano</surname><given-names>A</given-names></name><name><surname>Forzano</surname><given-names>C</given-names></name><name><surname>Palombo</surname><given-names>A</given-names></name></person-group><article-title>A novel dynamic simulation model for the thermo-economic analysis and optimisation of district heating systems</article-title><source>Energy Convers. Manage.</source><year>2020</year><volume>220</volume><fpage>113052</fpage><pub-id pub-id-type="doi">10.1016/j.enconman.2020.113052</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doroti&#x00107;</surname><given-names>H</given-names></name><name><surname>Puk&#x00161;ec</surname><given-names>T</given-names></name><name><surname>Dui&#x00107;</surname><given-names>N</given-names></name></person-group><article-title>Multi-objective optimization of district heating and cooling systems for a one-year time horizon</article-title><source>Energy</source><year>2019</year><volume>169</volume><fpage>319</fpage><lpage>328</lpage><pub-id pub-id-type="doi">10.1016/j.energy.2018.11.149</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guelpa</surname><given-names>E</given-names></name><name><surname>Verda</surname><given-names>V</given-names></name></person-group><article-title>Thermal energy storage in district heating and cooling systems: A review</article-title><source>Appl. Energy</source><year>2019</year><volume>252</volume><fpage>113474</fpage><pub-id pub-id-type="doi">10.1016/j.apenergy.2019.113474</pub-id></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buffa</surname><given-names>S</given-names></name><name><surname>Cozzini</surname><given-names>M</given-names></name><name><surname>D&#x02019;antoni</surname><given-names>M</given-names></name><name><surname>Baratieri</surname><given-names>M</given-names></name><name><surname>Fedrizzi</surname><given-names>R</given-names></name></person-group><article-title>5th generation district heating and cooling systems: A review of existing cases in Europe</article-title><source>Renew. Sustain. Energy Rev.</source><year>2019</year><volume>104</volume><fpage>504</fpage><lpage>522</lpage><pub-id pub-id-type="doi">10.1016/j.rser.2018.12.059</pub-id></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dang</surname><given-names>LM</given-names></name><name><surname>Lee</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Oh</surname><given-names>C</given-names></name><name><surname>Nguyen</surname><given-names>TN</given-names></name><name><surname>Song</surname><given-names>H-K</given-names></name><name><surname>Moon</surname><given-names>H</given-names></name></person-group><article-title>Daily and seasonal heat usage patterns analysis in heat networks</article-title><source>Sci. Rep.</source><year>2022</year><volume>12</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="pmid">34992227</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xue</surname><given-names>P</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name><name><surname>Zhou</surname><given-names>Z</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Fang</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name></person-group><article-title>Multi-step ahead forecasting of heat load in district heating systems using machine learning algorithms</article-title><source>Energy</source><year>2019</year><volume>188</volume><fpage>116085</fpage><pub-id pub-id-type="doi">10.1016/j.energy.2019.116085</pub-id></element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>J</given-names></name></person-group><article-title>A review of data mining technologies in building energy systems: Load prediction, pattern identification, fault detection and diagnosis</article-title><source>Energy Built Environ.</source><year>2020</year><volume>1</volume><fpage>149</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1016/j.enbenv.2019.11.003</pub-id></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>H</given-names></name><name><surname>Li</surname><given-names>G</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>C</given-names></name><name><surname>Huang</surname><given-names>R</given-names></name><name><surname>Huang</surname><given-names>Y</given-names></name></person-group><article-title>Machine learning-based thermal response time ahead energy demand prediction for building heating systems</article-title><source>Appl. Energy</source><year>2018</year><volume>221</volume><fpage>16</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1016/j.apenergy.2018.03.125</pub-id></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Hong</surname><given-names>T</given-names></name><name><surname>Piette</surname><given-names>MA</given-names></name></person-group><article-title>Building thermal load prediction through shallow machine learning and deep learning</article-title><source>Appl. Energy</source><year>2020</year><volume>263</volume><fpage>114683</fpage><pub-id pub-id-type="doi">10.1016/j.apenergy.2020.114683</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nageler</surname><given-names>P</given-names></name><name><surname>Koch</surname><given-names>A</given-names></name><name><surname>Mauthner</surname><given-names>F</given-names></name><name><surname>Leusbrock</surname><given-names>I</given-names></name><name><surname>Mach</surname><given-names>T</given-names></name><name><surname>Hochenauer</surname><given-names>C</given-names></name><name><surname>Heimrath</surname><given-names>R</given-names></name></person-group><article-title>Comparison of dynamic urban building energy models (UBEM): Sigmoid energy signature and physical modelling approach</article-title><source>Energy Build.</source><year>2018</year><volume>179</volume><fpage>333</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1016/j.enbuild.2018.09.034</pub-id></element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westermann</surname><given-names>P</given-names></name><name><surname>Deb</surname><given-names>C</given-names></name><name><surname>Schlueter</surname><given-names>A</given-names></name><name><surname>Evins</surname><given-names>R</given-names></name></person-group><article-title>Unsupervised learning of energy signatures to identify the heating system and building type using smart meter data</article-title><source>Appl. Energy</source><year>2020</year><volume>264</volume><fpage>114715</fpage><pub-id pub-id-type="doi">10.1016/j.apenergy.2020.114715</pub-id></element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>X</given-names></name><name><surname>Oyedele</surname><given-names>LO</given-names></name><name><surname>Ajayi</surname><given-names>AO</given-names></name><name><surname>Akinade</surname><given-names>OO</given-names></name><name><surname>Owolabi</surname><given-names>HA</given-names></name><name><surname>Ahmed</surname><given-names>A</given-names></name></person-group><article-title>Feature extraction and genetic algorithm enhanced adaptive deep neural network for energy consumption prediction in buildings</article-title><source>Renew. Sustain. Energy Rev.</source><year>2020</year><volume>131</volume><fpage>109980</fpage><pub-id pub-id-type="doi">10.1016/j.rser.2020.109980</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ntakolia</surname><given-names>C</given-names></name><name><surname>Anagnostis</surname><given-names>A</given-names></name><name><surname>Moustakidis</surname><given-names>S</given-names></name><name><surname>Karcanias</surname><given-names>N</given-names></name></person-group><article-title>Machine learning applied on the district heating and cooling sector: A review</article-title><source>Energy Syst.</source><year>2022</year><volume>13</volume><fpage>1</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1007/s12667-020-00405-9</pub-id></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guelpa</surname><given-names>E</given-names></name><name><surname>Marincioni</surname><given-names>L</given-names></name><name><surname>Capone</surname><given-names>M</given-names></name><name><surname>Deputato</surname><given-names>S</given-names></name><name><surname>Verda</surname><given-names>V</given-names></name></person-group><article-title>Thermal load prediction in district heating systems</article-title><source>Energy</source><year>2019</year><volume>176</volume><fpage>693</fpage><lpage>703</lpage><pub-id pub-id-type="doi">10.1016/j.energy.2019.04.021</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouleau</surname><given-names>J</given-names></name><name><surname>Gosselin</surname><given-names>L</given-names></name></person-group><article-title>Impacts of the COVID-19 lockdown on energy consumption in a Canadian social housing building</article-title><source>Appl. Energy</source><year>2021</year><volume>287</volume><fpage>116565</fpage><pub-id pub-id-type="doi">10.1016/j.apenergy.2021.116565</pub-id><?supplied-pmid 34608347?><pub-id pub-id-type="pmid">34608347</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Idowu</surname><given-names>S</given-names></name><name><surname>Saguna</surname><given-names>S</given-names></name><name><surname>&#x000c5;hlund</surname><given-names>C</given-names></name><name><surname>Schel&#x000e9;n</surname><given-names>O</given-names></name></person-group><article-title>Applied machine learning: Forecasting heat load in district heating system</article-title><source>Energy Build.</source><year>2016</year><volume>133</volume><fpage>478</fpage><lpage>488</lpage><pub-id pub-id-type="doi">10.1016/j.enbuild.2016.09.068</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bourdeau</surname><given-names>M</given-names></name><name><surname>Qiang Zhai</surname><given-names>X</given-names></name><name><surname>Nefzaoui</surname><given-names>E</given-names></name><name><surname>Guo</surname><given-names>X</given-names></name><name><surname>Chatellier</surname><given-names>P</given-names></name></person-group><article-title>Modeling and forecasting building energy consumption: A review of data-driven techniques</article-title><source>Sustain. Cities Soc.</source><year>2019</year><volume>48</volume><fpage>101533</fpage><pub-id pub-id-type="doi">10.1016/j.scs.2019.101533</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saloux</surname><given-names>E</given-names></name><name><surname>Candanedo</surname><given-names>JA</given-names></name></person-group><article-title>Forecasting district heating demand using machine learning algorithms</article-title><source>Energy Procedia</source><year>2018</year><volume>149</volume><fpage>59</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1016/j.egypro.2018.08.169</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>L&#x000f3;pez</surname><given-names>M</given-names></name><name><surname>Sans</surname><given-names>C</given-names></name><name><surname>Valero</surname><given-names>S</given-names></name><name><surname>Senabre</surname><given-names>C</given-names></name></person-group><article-title>Classification of special days in short-term load forecasting: The Spanish case study</article-title><source>Energies</source><year>2019</year><volume>12</volume><issue>7</issue><fpage>1253</fpage><pub-id pub-id-type="doi">10.3390/en12071253</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noussan</surname><given-names>M</given-names></name><name><surname>Jarre</surname><given-names>M</given-names></name><name><surname>Poggio</surname><given-names>A</given-names></name></person-group><article-title>Real operation data analysis on district heating load patterns</article-title><source>Energy</source><year>2017</year><volume>129</volume><fpage>70</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1016/j.energy.2017.04.079</pub-id></element-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sukparungsee</surname><given-names>S</given-names></name><name><surname>Areepong</surname><given-names>Y</given-names></name><name><surname>Taboran</surname><given-names>R</given-names></name></person-group><article-title>Exponentially weighted moving average&#x02014;Moving average charts for monitoring the process mean</article-title><source>PLoS ONE</source><year>2020</year><volume>15</volume><fpage>e0228208</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0228208</pub-id><?supplied-pmid 32059001?><pub-id pub-id-type="pmid">32059001</pub-id></element-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Harrell</surname><given-names>FE</given-names></name></person-group><source>General Aspects of Fitting Regression Models</source><year>2015</year><publisher-name>Springer</publisher-name><fpage>13</fpage><lpage>44</lpage></element-citation></ref><ref id="CR24"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Munkhdalai</surname><given-names>L</given-names></name><name><surname>Munkhdalai</surname><given-names>T</given-names></name><name><surname>Park</surname><given-names>KH</given-names></name><name><surname>Lee</surname><given-names>HG</given-names></name><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Ryu</surname><given-names>KH</given-names></name></person-group><article-title>Mixture of activation functions with extended min-max normalization for forex market prediction</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>183680</fpage><lpage>183691</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2959789</pub-id></element-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okada</surname><given-names>S</given-names></name><name><surname>Ohzeki</surname><given-names>M</given-names></name><name><surname>Taguchi</surname><given-names>S</given-names></name></person-group><article-title>Efficient partition of integer optimization problems with one-hot encoding</article-title><source>Sci. Rep.</source><year>2019</year><volume>9</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41598-019-49539-6</pub-id><pub-id pub-id-type="pmid">30626917</pub-id></element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>F</given-names></name><name><surname>O'Donnell</surname><given-names>LJ</given-names></name></person-group><source>Support Vector Regression</source><year>2020</year><publisher-name>Elsevier</publisher-name><fpage>123</fpage><lpage>140</lpage></element-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Lombardi</surname><given-names>F</given-names></name><name><surname>Han</surname><given-names>J</given-names></name></person-group><article-title>A stochastic computational multi-layer perceptron with backward propagation</article-title><source>IEEE Trans. Comput.</source><year>2018</year><volume>67</volume><fpage>1273</fpage><lpage>1286</lpage><pub-id pub-id-type="doi">10.1109/TC.2018.2817237</pub-id></element-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Azmi, S.S., Baliga, S. An Overview of Boosting Decision Tree Algorithms utilizing AdaBoost and XGBoost Boosting strategies. <italic>Int. Res. J. Eng. Technol.</italic><bold>2020</bold>, <italic>7</italic>.</mixed-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bent&#x000e9;jac</surname><given-names>C</given-names></name><name><surname>Cs&#x000f6;rg&#x00151;</surname><given-names>A</given-names></name><name><surname>Mart&#x000ed;nez-Mu&#x000f1;oz</surname><given-names>G</given-names></name></person-group><article-title>A comparative analysis of gradient boosting algorithms</article-title><source>Artif. Intell. Rev.</source><year>2021</year><volume>54</volume><fpage>1937</fpage><lpage>1967</lpage><pub-id pub-id-type="doi">10.1007/s10462-020-09896-5</pub-id></element-citation></ref><ref id="CR30"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><name><surname>Blondel</surname><given-names>M</given-names></name><name><surname>Prettenhofer</surname><given-names>P</given-names></name><name><surname>Weiss</surname><given-names>R</given-names></name><name><surname>Dubourg</surname><given-names>V</given-names></name><name><surname>Vanderplas</surname><given-names>J</given-names></name></person-group><article-title>Scikit-learn: Machine learning in Python</article-title><source>J. Mach. Learn. Res.</source><year>2011</year><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moosbauer</surname><given-names>J</given-names></name><name><surname>Herbinger</surname><given-names>J</given-names></name><name><surname>Casalicchio</surname><given-names>G</given-names></name><name><surname>Lindauer</surname><given-names>M</given-names></name><name><surname>Bischl</surname><given-names>B</given-names></name></person-group><article-title>Explaining hyperparameter optimization via partial dependence plots</article-title><source>Adv. Neural. Inf. Process. Syst.</source><year>2021</year><volume>34</volume><fpage>2280</fpage><lpage>2291</lpage></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Visani</surname><given-names>G</given-names></name><name><surname>Bagli</surname><given-names>E</given-names></name><name><surname>Chesani</surname><given-names>F</given-names></name><name><surname>Poluzzi</surname><given-names>A</given-names></name><name><surname>Capuzzo</surname><given-names>D</given-names></name></person-group><article-title>Statistical stability indices for LIME: Obtaining reliable explanations for machine learning models</article-title><source>J. Oper. Res. Soc.</source><year>2022</year><volume>73</volume><issue>1</issue><fpage>91</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1080/01605682.2020.1865846</pub-id></element-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Sundararajan, M., Najmi, A. The many Shapley values for model explanation. In Proceedings of the International conference on machine learning, 2020, 9269&#x02013;9278.</mixed-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chicco</surname><given-names>D</given-names></name><name><surname>Warrens</surname><given-names>MJ</given-names></name><name><surname>Jurman</surname><given-names>G</given-names></name></person-group><article-title>The coefficient of determination R-squared is more informative than SMAPE, MAE, MAPE, MSE and RMSE in regression analysis evaluation</article-title><source>PEERJ. Comput. Sci.</source><year>2021</year><volume>7</volume><fpage>e623</fpage><pub-id pub-id-type="doi">10.7717/peerj-cs.623</pub-id><?supplied-pmid 34307865?><pub-id pub-id-type="pmid">34307865</pub-id></element-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenwell</surname><given-names>BM</given-names></name></person-group><article-title>pdp: an R Package for constructing partial dependence plots</article-title><source>R J.</source><year>2017</year><volume>9</volume><issue>1</issue><fpage>421</fpage><pub-id pub-id-type="doi">10.32614/RJ-2017-016</pub-id></element-citation></ref><ref id="CR36"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Yuan</surname><given-names>Y</given-names></name><name><surname>Chen</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Guo</surname><given-names>Y</given-names></name><name><surname>Ahmad</surname><given-names>T</given-names></name></person-group><article-title>A novel energy demand prediction strategy for residential buildings based on ensemble learning</article-title><source>Energy Procedia</source><year>2019</year><volume>158</volume><fpage>3411</fpage><lpage>3416</lpage><pub-id pub-id-type="doi">10.1016/j.egypro.2019.01.935</pub-id></element-citation></ref><ref id="CR37"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>B&#x000fc;nning</surname><given-names>F</given-names></name><name><surname>Heer</surname><given-names>P</given-names></name><name><surname>Smith</surname><given-names>RS</given-names></name><name><surname>Lygeros</surname><given-names>J</given-names></name></person-group><article-title>Improved day ahead heating demand forecasting by online correction methods</article-title><source>Energy Build.</source><year>2020</year><volume>211</volume><fpage>109821</fpage><pub-id pub-id-type="doi">10.1016/j.enbuild.2020.109821</pub-id></element-citation></ref><ref id="CR38"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ivanko</surname><given-names>D</given-names></name><name><surname>S&#x000f8;rensen</surname><given-names>&#x000c5;L</given-names></name><name><surname>Nord</surname><given-names>N</given-names></name></person-group><article-title>Selecting the model and influencing variables for DHW heat use prediction in hotels in Norway</article-title><source>Energy Build.</source><year>2020</year><volume>228</volume><fpage>110441</fpage><pub-id pub-id-type="doi">10.1016/j.enbuild.2020.110441</pub-id></element-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="other">Minh, D., Wang, H.X., Li, Y.F. and Nguyen, T.N. Explainable artificial intelligence: A comprehensive review. <italic>Artif. Intell. Rev. </italic>2022, 1&#x02013;66.</mixed-citation></ref></ref-list></back></article>